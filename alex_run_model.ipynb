{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import logging\n",
    "import argparse\n",
    "import pyspark.sql.functions as F\n",
    "from argparse import RawTextHelpFormatter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark import SparkConf\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.types import DoubleType, IntegerType, BooleanType, StringType, NullType, DateType, TimestampType\n",
    "\n",
    "description= \"\"\n",
    "epilog= \"\"\n",
    "APP_NAME= \"pyspark_data_clean\"\n",
    "\n",
    "def quiet_py4j():\n",
    "    \"\"\" turn down spark logging for the test context \"\"\"\n",
    "    logger = logging.getLogger('py4j')\n",
    "    logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def spark_context():\n",
    "    \"\"\" fixture for creating a spark context\n",
    "    Args:\n",
    "        request: pytest.FixtureRequest object\n",
    "    \"\"\"\n",
    "    # debug use\n",
    "    conf = (SparkConf().setAppName(APP_NAME))\n",
    "    sc = SparkContext(conf=conf)\n",
    "    quiet_py4j()\n",
    "    return sc\n",
    "\n",
    "def get_clean_data(df_raw, is_realtime):\n",
    "\n",
    "    # Process 43 features according to guidelines\n",
    "    category_feature= [\n",
    "        \"reimbursementId\",\n",
    "        \"allocationType\",\n",
    "        \"applicantLevel\",\n",
    "        \"legalEntityCode\",\n",
    "        \"regionCode\",\n",
    "        \"appEmployeeName\",\n",
    "        \"costCenterCode\",\n",
    "        \"organizationCode\",\n",
    "        \"vendorCode\",\n",
    "        \"expenseId\",\n",
    "        \"city\",\n",
    "        \"destination\",\n",
    "        \"expensePaymentType\",\n",
    "        \"flightNo\",\n",
    "        \"mileage\",\n",
    "        \"placeOfDeparture\",\n",
    "        \"transportation\",\n",
    "        \"s_reimbursementId\",\n",
    "        \"expenseTypeCode\",\n",
    "        \"expenseTypeName\",\n",
    "        \"s_vendorCode\",\n",
    "        \"cid_dbsn\",\n",
    "        \"uid\"\n",
    "    ]\n",
    "    numeric_feature= [\n",
    "        \"cashAdvance\",\n",
    "        \"deductAmount\",\n",
    "        \"paidByCompany\",\n",
    "        \"totalBalanceOfReceivable\",\n",
    "        \"totalPayableAmount\",\n",
    "        \"totalReimbursementAmount\",\n",
    "        \"applyExpenseAmount\",\n",
    "        \"expenditure\",\n",
    "        \"quantity\",\n",
    "        \"unitPrice\"\n",
    "    ]\n",
    "    if is_realtime:\n",
    "        bool_feature= [\n",
    "            \"isPurchase\",\n",
    "            \"isRoundTrip\",\n",
    "            \"isHighRisk\"\n",
    "        ]\n",
    "    else:\n",
    "        bool_feature= [\n",
    "            \"isPurchase\",\n",
    "            \"isRoundTrip\",\n",
    "            \"isHighRisk\",\n",
    "            \"sizeOfNcList\"\n",
    "        ]\n",
    "    text_feature= [\n",
    "        \"comments\",\n",
    "        \"deductDemo\",\n",
    "        \"subject\",\n",
    "        \"expenseDescription\",\n",
    "        \"purpose\"\n",
    "    ]\n",
    "    time_series_feature1= [\n",
    "        \"beginDate\",\n",
    "        \"endDate\"\n",
    "    ]\n",
    "    time_series_feature2= [\n",
    "        \"applyDate\",\n",
    "        \"transactionDate\"\n",
    "    ]\n",
    "\n",
    "    fillempty = F.udf(lambda s: \"null\" if(s == \"\") else s, StringType())\n",
    "\n",
    "    # Process category features according to guidelines\n",
    "    for col_tmp in category_feature:\n",
    "        df_raw = df_raw.withColumn(col_tmp, df_raw[col_tmp].cast(\"string\"))\n",
    "    #    df_raw = df_raw.withColumn(col_tmp, fillempty(df_raw[col_tmp]))\n",
    "\n",
    "    # Process numeric features according to guidelines\n",
    "    for col_tmp in numeric_feature:\n",
    "        df_raw = df_raw.withColumn(col_tmp, df_raw[col_tmp].cast(\"double\"))\n",
    "    # TODO:01 test 1, test quantity 0 filled with 1\n",
    "    df_raw = df_raw.withColumn(\n",
    "        \"quantity\",\n",
    "        F.when(df_raw[\"quantity\"]==0, 1).otherwise(df_raw[\"quantity\"])\n",
    "        )\n",
    "\n",
    "    # Process bool features according to guidelines\n",
    "    for col_tmp in bool_feature:\n",
    "        df_raw = df_raw.withColumn(col_tmp, df_raw[col_tmp].cast(\"boolean\"))\n",
    "\n",
    "    if not is_realtime:\n",
    "        df_raw = df_raw.withColumnRenamed(\"sizeOfNcList\",\"isNC\")\n",
    "\n",
    "    # Process text features according to guidelines\n",
    "    for col_tmp in text_feature:\n",
    "        df_raw = df_raw.withColumn(col_tmp, df_raw[col_tmp].cast(\"string\"))\n",
    "    #    df_raw = df_raw.withColumn(col_tmp, fillempty(df_raw[col_tmp]))\n",
    "\n",
    "\n",
    "    # Process time series features according to guidelines\n",
    "    for col_tmp in time_series_feature1:\n",
    "        df_raw = df_raw.withColumn(\n",
    "            col_tmp,\n",
    "            F.to_date(\n",
    "                F.unix_timestamp(\n",
    "                    df_raw[col_tmp].cast(\"string\"),\"yyyyMMdd\"\n",
    "                    ).cast(\"timestamp\")))\n",
    "\n",
    "    for col_tmp in time_series_feature2:\n",
    "        df_raw = df_raw.withColumn(\n",
    "            col_tmp,\n",
    "            F.to_date(\n",
    "                F.from_unixtime(\n",
    "                    df_raw[col_tmp]/1000,\"yyyy-MM-dd\")))\n",
    "\n",
    "    # add year, month, day column in history data\n",
    "    df_clean_data = df_raw.withColumn(\n",
    "        \"year\",\n",
    "        F.year(df_raw[\"applyDate\"])).withColumn(\n",
    "            \"month\",\n",
    "            F.month(df_raw[\"applyDate\"])).withColumn(\n",
    "                \"day\",\n",
    "                F.dayofmonth(df_raw[\"applyDate\"]))\n",
    "\n",
    "    columns = [\n",
    "        \"uid\",\n",
    "        \"allocationtype\",\n",
    "        \"appemployeename\",\n",
    "        \"applicantlevel\",\n",
    "        \"applydate\",\n",
    "        \"applyexpenseamount\",\n",
    "        \"begindate\",\n",
    "        \"cashadvance\",\n",
    "        \"city\",\n",
    "        \"comments\",\n",
    "        \"costcentercode\",\n",
    "        \"deductamount\",\n",
    "        \"deductdemo\",\n",
    "        \"destination\",\n",
    "        \"enddate\",\n",
    "        \"expenditure\",\n",
    "        \"expensedescription\",\n",
    "        \"expenseid\",\n",
    "        \"expensepaymenttype\",\n",
    "        \"expensetypecode\",\n",
    "        \"expensetypename\",\n",
    "        \"flightno\",\n",
    "        \"ishighrisk\",\n",
    "        \"ispurchase\",\n",
    "        \"isroundtrip\",\n",
    "        \"legalentitycode\",\n",
    "        \"mileage\",\n",
    "        \"organizationcode\",\n",
    "        \"paidbycompany\",\n",
    "        \"placeofdeparture\",\n",
    "        \"purpose\",\n",
    "        \"quantity\",\n",
    "        \"regioncode\",\n",
    "        \"reimbursementid\",\n",
    "        \"s_reimbursementid\",\n",
    "        \"s_vendorcode\",\n",
    "        \"subject\",\n",
    "        \"submitted_date\",\n",
    "        \"totalbalanceofreceivable\",\n",
    "        \"totalpayableamount\",\n",
    "        \"totalreimbursementamount\",\n",
    "        \"transactiondate\",\n",
    "        \"transportation\",\n",
    "        \"unitprice\",\n",
    "        \"vendorcode\",\n",
    "        \"cid_dbsn\"\n",
    "    ]\n",
    "\n",
    "    if not is_realtime:\n",
    "        columns.extend([\"isNC\",\"year\",\"month\",\"day\"])\n",
    "\n",
    "    df_clean_data = df_clean_data.select(columns)\n",
    "\n",
    "    return df_clean_data\n",
    "\n",
    "# TODO:02 test 2, nc daily count\n",
    "def calculate_daily_NC(df_clean_data, field_name):\n",
    "    # count nc for cleaned daily data\n",
    "    df_NC = df_clean_data.filter(\n",
    "        df_clean_data[\"isnc\"] == True).groupby(\n",
    "            df_clean_data[\"cid_dbsn\"],\n",
    "            df_clean_data[field_name],\n",
    "            df_clean_data[\"applydate\"].alias(\"year_month_day\")\n",
    "            ).count().withColumnRenamed(\"count\",\"nccount\")\n",
    "    return df_NC\n",
    "        \n",
    "# TODO:03 test 3, nc count for 3 months\n",
    "def calculate_recent3m_NC(df_nc, field_name, current_date, duration = 90):\n",
    "\n",
    "    df_nc = df_nc.withColumn(\n",
    "        \"historydays\",\n",
    "        F.datediff(\n",
    "            F.lit(current_date),\n",
    "            df_nc[\"year_month_day\"])\n",
    "        )\n",
    "    #df_nc.show()\n",
    "    df_agg = df_nc.filter(\n",
    "        df_nc[\"historydays\"] < duration).groupby(\n",
    "            \"cid_dbsn\",\n",
    "            field_name).agg(\n",
    "                F.sum(\n",
    "                    df_nc[\"nccount\"]).alias(\n",
    "                        \"recent_total_nccount\"))\n",
    "    return df_agg\n",
    "\n",
    "# TODO:04 test 4, expense quantity daily count\n",
    "def calculate_daily_expense_quantity(df_clean_data, field_name, alias_name):\n",
    "\n",
    "    df_total = df_clean_data.groupby(\n",
    "        \"cid_dbsn\",\n",
    "        \"appemployeename\",\n",
    "        df_clean_data[\"applydate\"].alias(\"year_month_day\")\n",
    "        ).agg(\n",
    "            F.sum(\n",
    "                df_clean_data[field_name]).alias(alias_name))\n",
    "\n",
    "    return df_total\n",
    "\n",
    "# TODO:05 test 5, expense quantity count for recent 1 month\n",
    "def calculate_recent1m_expense(df_expense, field_name, alias_name, current_date, duration = 30):\n",
    "\n",
    "    df_expense = df_expense.withColumn(\n",
    "        \"historydays\",\n",
    "        F.datediff(\n",
    "            F.lit(current_date),\n",
    "            df_expense[\"year_month_day\"])\n",
    "        )\n",
    "    #df_expense.show()\n",
    "    df_agg = df_expense.filter(\n",
    "        df_expense[\"historydays\"] < duration).groupby(\n",
    "            \"cid_dbsn\",\n",
    "            \"appemployeename\").agg(\n",
    "                F.sum(\n",
    "                    df_expense[field_name]).alias(alias_name))\n",
    "\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc already loaded\n",
      "number of columns = 47\n",
      "number of rows = 1000\n"
     ]
    }
   ],
   "source": [
    "fn='/Volumes/data/Dropbox/Accenture/projects/iaudit_TnE_from_QianWei/data/sample3.parquet/part-r-00000-2275da01-e816-4f46-889a-fda29405b72d.gz.parquet'\n",
    "sql_file = '/Volumes/data/Dropbox/Accenture/projects/iaudit_TnE_from_QianWei/source/db/hive.sql'\n",
    "current_date = strftime(\"%Y-%m-%d\", gmtime())\n",
    "HistNC_d = 500\n",
    "HistExp_d = 500\n",
    "\n",
    "# DONE:20 Read raw data from previous step (ether history feed or hourly feed)\n",
    "try:\n",
    "    sc = spark_context()\n",
    "except:\n",
    "    print \"sc already loaded\"\n",
    "\n",
    "hiveContext = HiveContext(sc)\n",
    "hiveContext.setConf(\"hive.exec.dynamic.partition\", \"true\")\n",
    "hiveContext.setConf(\"hive.exec.dynamic.partition.mode\", \"nonstrict\")\n",
    "df_raw = hiveContext.read.format('parquet').load(fn).dropDuplicates(['uid'])\n",
    "\n",
    "l = len(df_raw.columns)\n",
    "print \"number of columns = %i\" %(l)\n",
    "print \"number of rows = %i\" %(df_raw.count())\n",
    "\n",
    "df_clean_data = get_clean_data(df_raw, 0)\n",
    "\n",
    "# Todo: Revise to use op.db_db\n",
    "\n",
    "#query_db = \"use {}_db\".format(op.db)\n",
    "#hiveContext.sql(query_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw_collect = df_raw.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(uid=u'2_4|10415|84364', allocationType=u'\\u62a5\\u9500\\u5355\\u5206\\u644a', appEmployeeName=u'davidysun(\\u5b59\\u745c)', applicantLevel=u'2', applyDate=1463068800000, applyExpenseAmount=500.0, beginDate=20160310, cashAdvance=0.0, city=u'\\u5317\\u4eac/\\u4e0a\\u6d77', comments=u'2016\\u5e743\\u670810\\u65e5-11\\u65e5\\uff0c\\u51fa\\u5dee\\u5317\\u4eac\\uff0c\\u62dc\\u8bbf\\u6dd8\\u5b9d\\u3001\\u5b66\\u9738\\u541b\\u5ba2\\u6237\\u3002', costCenterCode=u'0104A', deductAmount=0.0, deductDemo=u'', destination=u'', endDate=20160311, expenditure=0.0, expenseDescription=u'', expenseId=u'84364', expensePaymentType=u'', expenseTypeCode=u'', expenseTypeName=u'\\u5dee\\u65c5\\u8d39_\\u56fd\\u5185\\u5dee\\u65c5\\u8d39_\\u4f4f\\u5bbf\\u8d39', flightNo=u'', isHighRisk=0, isPurchase=False, isRoundTrip=0, legalEntityCode=u'T01', mileage=u'', organizationCode=u'0104A', paidByCompany=0.0, placeOfDeparture=u'', purpose=u'', quantity=0.0, regionCode=u'', reimbursementId=u'10415', s_reimbursementId=u'10415', s_vendorCode=u'null', subject=u'', submitted_date=u'20161019_12', totalBalanceOfReceivable=0.0, totalPayableAmount=1530.7, totalReimbursementAmount=1530.7, transactionDate=0, transportation=u'', unitPrice=0.0, vendorCode=u'null', cid_dbsn=u'2_4', sizeOfNcList=1)\n"
     ]
    }
   ],
   "source": [
    "print df_raw_collect[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------+\n",
      "|  database|           tableName|isTemporary|\n",
      "+----------+--------------------+-----------+\n",
      "|db_dropbox| costcenter_daily_nc|      false|\n",
      "|db_dropbox|costcenter_histor...|      false|\n",
      "|db_dropbox|employee_daily_ex...|      false|\n",
      "|db_dropbox|   employee_daily_nc|      false|\n",
      "|db_dropbox|employee_daily_qu...|      false|\n",
      "|db_dropbox|employee_history_...|      false|\n",
      "|db_dropbox| employee_history_nc|      false|\n",
      "|db_dropbox|employee_history_...|      false|\n",
      "|db_dropbox|             feature|      false|\n",
      "|db_dropbox|  feature_importance|      false|\n",
      "|db_dropbox|      history_record|      false|\n",
      "|db_dropbox|legalentity_daily_nc|      false|\n",
      "|db_dropbox|legalentity_histo...|      false|\n",
      "|db_dropbox|organization_dail...|      false|\n",
      "|db_dropbox|organization_hist...|      false|\n",
      "|db_dropbox|              output|      false|\n",
      "|db_dropbox|   output_evaluation|      false|\n",
      "|db_dropbox|  prediction_history|      false|\n",
      "+----------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    hiveContext.sql('use db_dropbox')\n",
    "except:\n",
    "    with open(sql_file) as sql_init:\n",
    "        sql_init_str = sql_init.read()\n",
    "        sql_query = sql_init_str.replace('\\r\\n', '').split(';')\n",
    "        for item in sql_query:\n",
    "            try:\n",
    "                hiveContext.sql(item)\n",
    "            except:\n",
    "                print(\"SQL error!\")\n",
    "    # DONE:0 Save processed data into hive table history_data\n",
    "    df_clean_data.write.insertInto(\"history_record\",overwrite=False)\n",
    "\n",
    "    #df_clean_data.write.partitionBy('year','month','day').insertInto(\"history_record\",overwrite=False)\n",
    "\n",
    "    print \"History/daily process >> data clean: {}\".format(\"done!\")\n",
    "\n",
    "\n",
    "    hiveContext.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean_data.write.insertInto(\"history_record\",overwrite=False)\n",
    "data_history_record = hiveContext.sql('select * from history_record').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  uid allocationtype   appemployeename applicantlevel  \\\n",
      "0     2_4|10415|84363          报销单分摊     davidysun(孙瑜)              2   \n",
      "1     2_4|10415|84364          报销单分摊     davidysun(孙瑜)              2   \n",
      "2      2_4|6184|45118          报销单分摊        jianhe(何剑)              2   \n",
      "3      2_4|9163|73880          报销单分摊     byronwang(王刚)              2   \n",
      "4       2_4|1964|9362          报销单分摊      beatafu(付红艳)              2   \n",
      "5      2_4|2338|12389          报销单分摊     tedgzcao(曹冠中)              2   \n",
      "6    2_4|24488|203587          报销单分摊         haoma(马好)              2   \n",
      "7      2_4|2482|13728          报销单分摊    kevinxhxu(许辉旭)              2   \n",
      "8      2_4|2643|14977          报销单分摊     teemoliu(刘沛城)              2   \n",
      "9      2_4|3988|26176          报销单分摊     loiszhang(张璐)              2   \n",
      "10     2_4|3989|26191          报销单分摊     loiszhang(张璐)              2   \n",
      "11     2_4|6184|45123          报销单分摊        jianhe(何剑)              2   \n",
      "12     2_4|6185|45148          报销单分摊        jianhe(何剑)              2   \n",
      "13     2_4|8101|64035          报销单分摊       yingdai(戴颖)              2   \n",
      "14   2_4|12670|103708          报销单分摊   disenzhang(张东轩)              2   \n",
      "15     2_4|6184|45109          报销单分摊        jianhe(何剑)              2   \n",
      "16     2_4|6184|45110          报销单分摊        jianhe(何剑)              2   \n",
      "17     2_4|6185|45132          报销单分摊        jianhe(何剑)              2   \n",
      "18     2_4|7646|60146          报销单分摊  harveyzhang(张继龙)              2   \n",
      "19      2_4|1166|2667          报销单分摊      xiangxia(夏翔)              2   \n",
      "20   2_4|15590|127645          报销单分摊     ajerryli(李明同)              2   \n",
      "21   2_4|16101|131659          报销单分摊      jienfei(费戟恩)              2   \n",
      "22    2_4|10415|84362          报销单分摊     davidysun(孙瑜)              2   \n",
      "23      2_4|1929|9079          报销单分摊      myragong(龚雪)              2   \n",
      "24     2_4|2436|13198          报销单分摊      jiangtao(姜涛)              2   \n",
      "25     2_4|5291|37722          报销单分摊       yuedong(董悦)              2   \n",
      "26     2_4|5302|37822          报销单分摊    jellyzheng(郑沁)              2   \n",
      "27     2_4|6141|44857          报销单分摊     edithwang(王旋)              2   \n",
      "28   2_4|12670|103705          报销单分摊   disenzhang(张东轩)              2   \n",
      "29   2_4|19269|157694          报销单分摊    jokerlili(李亚鹏)              2   \n",
      "..                ...            ...               ...            ...   \n",
      "970    2_4|2442|13242          报销单分摊      jiangtao(姜涛)              2   \n",
      "971  2_4|24488|203589          报销单分摊         haoma(马好)              2   \n",
      "972    2_4|2482|13715          报销单分摊    kevinxhxu(许辉旭)              2   \n",
      "973    2_4|2482|13742          报销单分摊    kevinxhxu(许辉旭)              2   \n",
      "974    2_4|2528|14190          报销单分摊        paulhe(贺鹏)              2   \n",
      "975    2_4|2708|15448          报销单分摊        steve(聂志明)              2   \n",
      "976    2_4|2882|16954          报销单分摊      lilyfang(方丽)              2   \n",
      "977    2_4|4869|34026          报销单分摊    haibodeng(邓海波)              2   \n",
      "978    2_4|5777|41809          报销单分摊      evanpeng(彭伟)              1   \n",
      "979     2_4|1188|2952          报销单分摊   cammyzhang(张萍萍)              2   \n",
      "980     2_4|1554|6339          报销单分摊    reuszhang(张一斌)              2   \n",
      "981  2_4|16161|132065          报销单分摊      julieliu(柳娟)              2   \n",
      "982    2_4|3559|22629          报销单分摊     greatgong(龚伟)              2   \n",
      "983    2_4|3639|23084          报销单分摊     suphieli(李兰卿)              2   \n",
      "984  2_4|14050|114944          报销单分摊   huixianlei(雷慧贤)              2   \n",
      "985  2_4|15821|129443          报销单分摊    leedouwang(王力)              2   \n",
      "986    2_4|8102|64047          报销单分摊       yingdai(戴颖)              2   \n",
      "987    2_4|8102|64049          报销单分摊       yingdai(戴颖)              2   \n",
      "988    2_4|2346|12482          报销单分摊      hertzhu(胡泽锐)              2   \n",
      "989    2_4|2482|13734          报销单分摊    kevinxhxu(许辉旭)              2   \n",
      "990    2_4|4897|34193          报销单分摊    maggiecui(崔嘉卉)              2   \n",
      "991    2_4|6185|45138          报销单分摊        jianhe(何剑)              2   \n",
      "992     2_4|1166|2662          报销单分摊      xiangxia(夏翔)              2   \n",
      "993  2_4|16101|131656          报销单分摊      jienfei(费戟恩)              2   \n",
      "994     2_4|1929|9080          报销单分摊      myragong(龚雪)              2   \n",
      "995    2_4|2482|13708          报销单分摊    kevinxhxu(许辉旭)              2   \n",
      "996    2_4|2482|13735          报销单分摊    kevinxhxu(许辉旭)              2   \n",
      "997    2_4|3297|20609          报销单分摊     simonxue(薛文卿)              2   \n",
      "998    2_4|6185|45137          报销单分摊        jianhe(何剑)              2   \n",
      "999    2_4|8102|64051          报销单分摊       yingdai(戴颖)              2   \n",
      "\n",
      "      applydate  applyexpenseamount   begindate  cashadvance   city  \\\n",
      "0    2016-05-13               187.5  2016-03-10          0.0          \n",
      "1    2016-05-13               500.0  2016-03-10          0.0  北京/上海   \n",
      "2    2016-04-25                16.3  2016-02-26          0.0          \n",
      "3    2016-05-26                40.0  2016-05-17          0.0          \n",
      "4    2016-05-30                25.0  2016-05-01          0.0          \n",
      "5    2016-05-25                58.0  2016-05-21          0.0          \n",
      "6    2016-05-10              5500.0  2016-03-27          0.0  广州/深圳   \n",
      "7    2016-05-15                44.0  2016-03-01          0.0          \n",
      "8    2016-05-16                50.8  2016-02-16          0.0          \n",
      "9    2016-03-10                28.4  2015-12-30          0.0          \n",
      "10   2016-03-10                70.0  2015-12-23          0.0          \n",
      "11   2016-04-25                12.7  2016-03-02          0.0          \n",
      "12   2016-04-14                19.3  2016-01-30          0.0          \n",
      "13   2016-05-27               500.0  2016-03-31          0.0  北京/上海   \n",
      "14   2016-03-25                20.0  2016-02-24          0.0          \n",
      "15   2016-04-25                12.5  2016-02-02          0.0          \n",
      "16   2016-04-25                16.1  2016-02-03          0.0          \n",
      "17   2016-04-14                16.3  2016-01-08          0.0          \n",
      "18   2016-05-10                72.4  2016-04-21          0.0          \n",
      "19   2016-05-30               279.0  2016-05-07          0.0          \n",
      "20   2016-05-24               571.0  2016-05-18          0.0          \n",
      "21   2016-05-19                10.0  2016-05-05          0.0          \n",
      "22   2016-05-13                34.0  2016-03-10          0.0          \n",
      "23   2016-05-13               564.0  2016-04-08          0.0          \n",
      "24   2016-05-17               800.0  2016-04-05          0.0          \n",
      "25   2016-05-13                58.0  2016-03-10          0.0          \n",
      "26   2016-05-18                16.0  2015-11-25          0.0          \n",
      "27   2016-04-21                22.0  2016-03-24          0.0          \n",
      "28   2016-03-25                24.0  2016-01-26          0.0          \n",
      "29   2016-04-21                27.0  2016-04-18          0.0          \n",
      "..          ...                 ...         ...          ...    ...   \n",
      "970  2016-05-17                25.6  2016-03-12          0.0          \n",
      "971  2016-05-10                61.0  2016-04-25          0.0          \n",
      "972  2016-05-15                29.0  2016-01-20          0.0          \n",
      "973  2016-05-15                37.0  2016-04-06          0.0          \n",
      "974  2016-05-26                62.5  2016-05-24          0.0          \n",
      "975  2016-05-30               175.4  2016-05-26          0.0          \n",
      "976  2016-05-17                66.2  2016-05-04          0.0          \n",
      "977  2016-04-05               644.0  2016-03-16          0.0  成都/杭州   \n",
      "978  2016-05-23                47.0  2016-05-19          0.0          \n",
      "979  2016-05-30               133.0  2016-05-05          0.0          \n",
      "980  2016-05-23                70.0  2016-05-04          0.0          \n",
      "981  2016-04-01               500.0  2016-01-24          0.0  广州/深圳   \n",
      "982  2016-03-14                35.8  2016-02-29          0.0          \n",
      "983  2016-05-02                18.0  2016-04-28          0.0          \n",
      "984  2016-05-17               145.0  2016-03-07          0.0          \n",
      "985  2016-05-05               500.0  2016-03-23          0.0  广州/深圳   \n",
      "986  2016-05-27                10.0  2016-04-18          0.0          \n",
      "987  2016-05-27                10.0  2016-04-20          0.0          \n",
      "988  2016-05-13                72.0  2016-03-30          0.0          \n",
      "989  2016-05-15                44.0  2016-03-16          0.0          \n",
      "990  2016-05-23               216.0  2016-01-13          0.0          \n",
      "991  2016-04-14                21.5  2016-01-15          0.0          \n",
      "992  2016-05-30                45.0  2016-05-07          0.0          \n",
      "993  2016-05-19                27.0  2016-05-05          0.0          \n",
      "994  2016-05-13               193.0  2016-04-12          0.0          \n",
      "995  2016-05-15                35.0  2016-01-09          0.0          \n",
      "996  2016-05-15                45.0  2016-03-17          0.0          \n",
      "997  2016-05-27               410.0  2016-03-13          0.0          \n",
      "998  2016-04-14                27.6  2016-01-14          0.0          \n",
      "999  2016-05-27                10.0  2016-04-21          0.0          \n",
      "\n",
      "                                              comments ...  \\\n",
      "0                      2016年3月10日-11日，出差北京，拜访淘宝、学霸君客户。 ...   \n",
      "1                      2016年3月10日-11日，出差北京，拜访淘宝、学霸君客户。 ...   \n",
      "2                                2015年2月到2016年3月，交通费报销 ...   \n",
      "3                                             手游实名项目加班 ...   \n",
      "4                                 201604--201605加班打车费用 ...   \n",
      "5                           2016年5月21日~5月23日，出差上海，职业联赛 ...   \n",
      "6                                         深圳报道，15日差旅报销 ...   \n",
      "7                                2015.12-2016.04加班打车报销 ...   \n",
      "8                                              夜间交通费报销 ...   \n",
      "9    12.1-12.10/12.29-1.5/1.18-1.22/1.25-1.27/3.1-3... ...   \n",
      "10                                                晚上加班 ...   \n",
      "11                               2015年2月到2016年3月，交通费报销 ...   \n",
      "12   原始单据：C105-160413-2184707\\r\\n2015年1月到2016年2月，交通费报销 ...   \n",
      "13                                      星巴克项目 上海会议 4月初 ...   \n",
      "14                         2016年1月26日-2016年3月25日，交通费报销 ...   \n",
      "15                               2015年2月到2016年3月，交通费报销 ...   \n",
      "16                               2015年2月到2016年3月，交通费报销 ...   \n",
      "17   原始单据：C105-160413-2184707\\r\\n2015年1月到2016年2月，交通费报销 ...   \n",
      "18   2016年，4.21-4.22日广州，微信支付服务商大会、宝洁合作、境外支付培训、卡券培训会议�� ...   \n",
      "19   2016年5月7日、2016年5月16日期间司机王电雷由徐州返回采集上海及从上海回家所产的交... ...   \n",
      "20                            湖南卫视2档热门综艺节目合作，首次会面礼品+招待 ...   \n",
      "21                 2016年4月29日，5月4日-5月6日 北京 参加欧莱雅内容营销会议 ...   \n",
      "22                     2016年3月10日-11日，出差北京，拜访淘宝、学霸君客户。 ...   \n",
      "23                                      2016年4月 客情关系维护 ...   \n",
      "24                                      2016年4月，重点客户宴请 ...   \n",
      "25                                               早班打车费 ...   \n",
      "26                                             夜间加班交通费 ...   \n",
      "27                                               3月交通费 ...   \n",
      "28                         2016年1月26日-2016年3月25日，交通费报销 ...   \n",
      "29                2016年4月18日到4月21日去石家庄参加净慧长老三周年示祭法会报道。 ...   \n",
      "..                                                 ... ...   \n",
      "970                                2016年3月，渠道销售人员市内交通费 ...   \n",
      "971                                       深圳报道，15日差旅报销 ...   \n",
      "972                              2015.12-2016.04加班打车报销 ...   \n",
      "973                              2015.12-2016.04加班打车报销 ...   \n",
      "974                  2016年5月24日-2016年5月24日，出差广州TIT，开会。 ...   \n",
      "975                         2016年5月26日-28日，出差北京，参加GADC ...   \n",
      "976                2016年5月4日，出差深圳，为KSH会议分享。（酒店与其他同事共用） ...   \n",
      "977                          2016年3月16日 ~ 3月18日参加AVS会议 ...   \n",
      "978  2016年5月18日-5月22日出差厦门，拜访银鹭集团广告部全体成员，市场中心曾琦，销售副总... ...   \n",
      "979  原始单据：C104-160530-2248826\\r\\n2016-05-05  21:47-... ...   \n",
      "980                             早班上班及早班加班后下班及下午班，打车费用。 ...   \n",
      "981                                               部门年会 ...   \n",
      "982           原始单据：C105-160307-2128570\\r\\n2月29日，广州专业培训 ...   \n",
      "983                                     文化部备案与研发沟通版本内容 ...   \n",
      "984  3月招待,但是审批邮件因手误，把“3月”写成“2月”，但是具体每笔费用的日期，都是��明是3... ...   \n",
      "985       游戏加速项目相关，跟snowwei，caesarcai去广州和合作方开会，沟通合作方案。 ...   \n",
      "986                                            加班回家打车费 ...   \n",
      "987                                            加班回家打车费 ...   \n",
      "988                                               加班打车 ...   \n",
      "989                              2015.12-2016.04加班打车报销 ...   \n",
      "990                                            1月销售招待费 ...   \n",
      "991  原始单据：C105-160413-2184707\\r\\n2015年1月到2016年2月，交通费报销 ...   \n",
      "992  2016年5月7日、2016年5月16日期间司机王电雷由徐州返回采集上海及从上海回家所产的交... ...   \n",
      "993                2016年4月29日，5月4日-5月6日 北京 参加欧莱雅内容营销会议 ...   \n",
      "994                                     2016年4月 客情关系维护 ...   \n",
      "995                              2015.12-2016.04加班打车报销 ...   \n",
      "996                              2015.12-2016.04加班打车报销 ...   \n",
      "997                                               业务交流 ...   \n",
      "998  原始单据：C105-160413-2184707\\r\\n2015年1月到2016年2月，交通费报销 ...   \n",
      "999                                            加班回家打车费 ...   \n",
      "\n",
      "    totalreimbursementamount  transactiondate transportation unitprice  \\\n",
      "0                    1530.70       1970-01-01                      0.0   \n",
      "1                    1530.70       1970-01-01                      0.0   \n",
      "2                     322.50       1970-01-01                      0.0   \n",
      "3                     105.60       1970-01-01                      0.0   \n",
      "4                     106.00       1970-01-01                      0.0   \n",
      "5                     861.90       1970-01-01                      0.0   \n",
      "6                    5694.00       1970-01-01                      0.0   \n",
      "7                    1765.00       1970-01-01                      0.0   \n",
      "8                    1765.40       1970-01-01                      0.0   \n",
      "9                    5238.00       1970-01-01                      0.0   \n",
      "10                    502.00       1970-01-01                      0.0   \n",
      "11                    322.50       1970-01-01                      0.0   \n",
      "12                    425.90       1970-01-01                      0.0   \n",
      "13                   1805.50       1970-01-01                      0.0   \n",
      "14                    124.00       1970-01-01                      0.0   \n",
      "15                    322.50       1970-01-01                      0.0   \n",
      "16                    322.50       1970-01-01                      0.0   \n",
      "17                    425.90       1970-01-01                      0.0   \n",
      "18                   1323.30       1970-01-01                      0.0   \n",
      "19                    892.50       1970-01-01                      0.0   \n",
      "20                    995.00       1970-01-01                      0.0   \n",
      "21                   1220.50       1970-01-01                      0.0   \n",
      "22                   1530.70       1970-01-01                      0.0   \n",
      "23                   1221.00       1970-01-01                      0.0   \n",
      "24                   1500.00       1970-01-01                      0.0   \n",
      "25                    792.00       1970-01-01                      0.0   \n",
      "26                    260.64       1970-01-01                      0.0   \n",
      "27                    993.80       1970-01-01                      0.0   \n",
      "28                    124.00       1970-01-01                      0.0   \n",
      "29                    677.50       1970-01-01                      0.0   \n",
      "..                       ...              ...            ...       ...   \n",
      "970                   800.00       1970-01-01                      0.0   \n",
      "971                  5694.00       1970-01-01                      0.0   \n",
      "972                  1765.00       1970-01-01                      0.0   \n",
      "973                  1765.00       1970-01-01                      0.0   \n",
      "974                   188.50       1970-01-01                      0.0   \n",
      "975                  1983.00       1970-01-01                      0.0   \n",
      "976                   526.90       1970-01-01                      0.0   \n",
      "977                   817.20       1970-01-01                      0.0   \n",
      "978                  2667.20       1970-01-01                      0.0   \n",
      "979                   770.00       1970-01-01                      0.0   \n",
      "980                   578.00       1970-01-01                      0.0   \n",
      "981                  1053.40       1970-01-01                      0.0   \n",
      "982                   280.30       1970-01-01                      0.0   \n",
      "983                  1653.50       1970-01-01                      0.0   \n",
      "984                  2622.00       1970-01-01                      0.0   \n",
      "985                   687.50       1970-01-01                      0.0   \n",
      "986                   100.00       1970-01-01                      0.0   \n",
      "987                   100.00       1970-01-01                      0.0   \n",
      "988                  1284.00       1970-01-01                      0.0   \n",
      "989                  1765.00       1970-01-01                      0.0   \n",
      "990                  8494.00       1970-01-01                      0.0   \n",
      "991                   425.90       1970-01-01                      0.0   \n",
      "992                   892.50       1970-01-01                      0.0   \n",
      "993                  1220.50       1970-01-01                      0.0   \n",
      "994                  1221.00       1970-01-01                      0.0   \n",
      "995                  1765.00       1970-01-01                      0.0   \n",
      "996                  1765.00       1970-01-01                      0.0   \n",
      "997                  4434.00       1970-01-01                      0.0   \n",
      "998                   425.90       1970-01-01                      0.0   \n",
      "999                   100.00       1970-01-01                      0.0   \n",
      "\n",
      "    vendorcode  cid_dbsn   isNC  year month day  \n",
      "0         null       2_4  False  2016     5  13  \n",
      "1         null       2_4   True  2016     5  13  \n",
      "2         null       2_4  False  2016     4  25  \n",
      "3         null       2_4  False  2016     5  26  \n",
      "4         null       2_4  False  2016     5  30  \n",
      "5         null       2_4  False  2016     5  25  \n",
      "6         null       2_4   True  2016     5  10  \n",
      "7         null       2_4  False  2016     5  15  \n",
      "8         null       2_4  False  2016     5  16  \n",
      "9         null       2_4  False  2016     3  10  \n",
      "10        null       2_4  False  2016     3  10  \n",
      "11        null       2_4  False  2016     4  25  \n",
      "12        null       2_4  False  2016     4  14  \n",
      "13        null       2_4  False  2016     5  27  \n",
      "14        null       2_4  False  2016     3  25  \n",
      "15        null       2_4  False  2016     4  25  \n",
      "16        null       2_4  False  2016     4  25  \n",
      "17        null       2_4  False  2016     4  14  \n",
      "18        null       2_4  False  2016     5  10  \n",
      "19        null       2_4  False  2016     5  30  \n",
      "20        null       2_4   True  2016     5  24  \n",
      "21        null       2_4  False  2016     5  19  \n",
      "22        null       2_4  False  2016     5  13  \n",
      "23        null       2_4  False  2016     5  13  \n",
      "24        null       2_4  False  2016     5  17  \n",
      "25        null       2_4  False  2016     5  13  \n",
      "26        null       2_4  False  2016     5  18  \n",
      "27        null       2_4  False  2016     4  21  \n",
      "28        null       2_4  False  2016     3  25  \n",
      "29        null       2_4   True  2016     4  21  \n",
      "..         ...       ...    ...   ...   ...  ..  \n",
      "970       null       2_4  False  2016     5  17  \n",
      "971       null       2_4  False  2016     5  10  \n",
      "972       null       2_4  False  2016     5  15  \n",
      "973       null       2_4  False  2016     5  15  \n",
      "974       null       2_4  False  2016     5  26  \n",
      "975       null       2_4  False  2016     5  30  \n",
      "976       null       2_4  False  2016     5  17  \n",
      "977       null       2_4  False  2016     4   5  \n",
      "978       null       2_4  False  2016     5  23  \n",
      "979       null       2_4  False  2016     5  30  \n",
      "980       null       2_4  False  2016     5  23  \n",
      "981       null       2_4  False  2016     4   1  \n",
      "982       null       2_4  False  2016     3  14  \n",
      "983       null       2_4  False  2016     5   2  \n",
      "984       null       2_4  False  2016     5  17  \n",
      "985       null       2_4  False  2016     5   5  \n",
      "986       null       2_4  False  2016     5  27  \n",
      "987       null       2_4  False  2016     5  27  \n",
      "988       null       2_4  False  2016     5  13  \n",
      "989       null       2_4  False  2016     5  15  \n",
      "990       null       2_4  False  2016     5  23  \n",
      "991       null       2_4  False  2016     4  14  \n",
      "992       null       2_4  False  2016     5  30  \n",
      "993       null       2_4  False  2016     5  19  \n",
      "994       null       2_4  False  2016     5  13  \n",
      "995       null       2_4  False  2016     5  15  \n",
      "996       null       2_4  False  2016     5  15  \n",
      "997       null       2_4  False  2016     5  27  \n",
      "998       null       2_4  False  2016     4  14  \n",
      "999       null       2_4  False  2016     5  27  \n",
      "\n",
      "[1000 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "x = df_clean_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('/Users/huaijianzhang/nlp/iaudit_1000_dataset.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate daily NC and expense >> done!\n",
      "calculate recent NC and expense history >> done!\n"
     ]
    }
   ],
   "source": [
    "for id, table_name in (\n",
    "        (\"costcentercode\",\"costcenter_daily_nc\"),\n",
    "        (\"legalentitycode\",\"legalentity_daily_nc\"),\n",
    "        (\"organizationcode\",\"organization_daily_nc\"),\n",
    "        (\"appemployeename\",\"employee_daily_nc\")\n",
    "    ):\n",
    "    df_daily_nc = calculate_daily_NC(df_clean_data, id)\n",
    "    # append to daily table\n",
    "    df_daily_nc.write.insertInto(table_name, overwrite= False)\n",
    "\n",
    "for table_name, field_name, alias_name in (\n",
    "        (\"employee_daily_expense\", \"applyexpenseamount\", \"totalexpense\"),\n",
    "        (\"employee_daily_quantity\", \"quantity\", \"totalquantity\")\n",
    "    ):\n",
    "    df_daily_expense_quantity = calculate_daily_expense_quantity(df_clean_data, field_name, alias_name)\n",
    "    # append to daily table\n",
    "    df_daily_expense_quantity.write.insertInto(table_name, overwrite = False)\n",
    "\n",
    "print \"calculate daily NC and expense >> {}\".format(\"done!\")\n",
    "\n",
    "for id, daily_table_name, history_table_name in (\n",
    "        (\"costcentercode\",\"costcenter_daily_nc\",\"costcenter_history_nc\"),\n",
    "        (\"legalentitycode\",\"legalentity_daily_nc\",\"legalentity_history_nc\"),\n",
    "        (\"organizationcode\",\"organization_daily_nc\",\"organization_history_nc\"),\n",
    "        (\"appemployeename\",\"employee_daily_nc\",\"employee_history_nc\")\n",
    "    ):\n",
    "    df_nc = hiveContext.table(daily_table_name)\n",
    "    df_recent_NC = calculate_recent3m_NC(df_nc, id , current_date, HistNC_d)\n",
    "    df_recent_NC.write.insertInto(history_table_name, overwrite = True)\n",
    "\n",
    "for field_name, alias_name, daily_table_name, history_table_name in (\n",
    "        (\"totalexpense\",\"recent_total_expense\",\"employee_daily_expense\",\"employee_history_expense\"),\n",
    "        (\"totalquantity\",\"recent_total_quantity\",\"employee_daily_quantity\",\"employee_history_quantity\")\n",
    "    ):\n",
    "    df_expense = hiveContext.table(daily_table_name)\n",
    "    df_recent_expense = calculate_recent1m_expense(df_expense, field_name, alias_name, current_date, HistExp_d)\n",
    "    df_recent_expense.write.insertInto(history_table_name, overwrite = True)\n",
    "\n",
    "print \"calculate recent NC and expense history >> {}\".format(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import argparse\n",
    "import pyspark.sql.functions as F\n",
    "from argparse import RawTextHelpFormatter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from pyspark import HiveContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.types import DoubleType, IntegerType, BooleanType, StringType, NullType, DateType, TimestampType\n",
    "\n",
    "\n",
    "description= \"\"\n",
    "epilog= \"\"\n",
    "APP_NAME= \"pyspark_features\"\n",
    "\n",
    "def quiet_py4j():\n",
    "    \"\"\" turn down spark logging for the test context \"\"\"\n",
    "    logger = logging.getLogger('py4j')\n",
    "    logger.setLevel(logging.ERROR)\n",
    "\n",
    "def spark_context():\n",
    "    \"\"\" fixture for creating a spark context\n",
    "    Args:\n",
    "        request: pytest.FixtureRequest object\n",
    "    \"\"\"\n",
    "    conf = (SparkConf().setAppName(APP_NAME))\n",
    "    sc = SparkContext(conf=conf)\n",
    "    quiet_py4j()\n",
    "    return sc\n",
    "\n",
    "def normalize_features(df_feature):\n",
    "    numeric_feature= [\n",
    "        \"cashAdvance\",\n",
    "        \"deductAmount\",\n",
    "        #\"paidByCompany\",\n",
    "        #\"totalBalanceOfReceivable\",\n",
    "        \"totalPayableAmount\",\n",
    "        \"totalReimbursementAmount\",\n",
    "        \"applyExpenseAmount\",\n",
    "        #\"expenditure\",\n",
    "        #\"quantity\",\n",
    "        #\"unitPrice\",\n",
    "        #\"duration\",\n",
    "        #\"totalexpensequantity\",\n",
    "        #\"costcenterhistorync\",\n",
    "        #\"legalentityhistorync\",\n",
    "        #\"organizationhistorync\",\n",
    "        #\"employeehistorync\",\n",
    "        \"employeerecentexpense\"\n",
    "        #\"employeerecentexpensequantity\"\n",
    "    ]\n",
    "    for col in numeric_feature:\n",
    "        df_feature = df_feature.withColumn(col, F.log1p(df_feature[col]))\n",
    "\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_record_features(df_clean_data):\n",
    "    # TODO:01 test 1, duration calculation\n",
    "    # TODO:02 test 2, totalquantity calculation\n",
    "\n",
    "    df_clean_data= df_clean_data.withColumn(\n",
    "        \"duration\",\n",
    "        F.datediff(\n",
    "            df_clean_data[\"enddate\"],\n",
    "            df_clean_data[\"begindate\"]) + 1)\n",
    "\n",
    "    df_totalQuantity = df_clean_data.groupby(\n",
    "        df_clean_data[\"reimbursementid\"], df_clean_data[\"cid_dbsn\"]).agg(\n",
    "            F.sum(df_clean_data[\"quantity\"]).alias(\n",
    "                \"totalexpensequantity\"))\n",
    "\n",
    "    df_feature_data = df_clean_data.join(\n",
    "        df_totalQuantity,\n",
    "        [\"reimbursementid\", \"cid_dbsn\"],\n",
    "        \"left_outer\")\n",
    "\n",
    "    return df_feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(df_clean_data, hiveContext, is_realtime):\n",
    "    # TODO:03 test 3, test data correctly referenced: costcenterhistorync, legalentityhistorync, organizationhistorync, employeehistorync, employeerecentexpense, employeerecentexpensequantity\n",
    "\n",
    "    # add detail and master record features\n",
    "    df_feature_data = get_record_features(df_clean_data)\n",
    "\n",
    "    # read hive tables of aggregated nc count/expense\n",
    "    # TODO: remove use tne_db\n",
    "    costcenter_agg_nc = hiveContext.table(\n",
    "        \"costcenter_history_nc\").withColumnRenamed(\n",
    "            \"recent_total_nccount\",\n",
    "            \"costcenterhistorync\")\n",
    "\n",
    "    legalentity_agg_nc = hiveContext.table(\n",
    "        \"legalentity_history_nc\").withColumnRenamed(\n",
    "            \"recent_total_nccount\",\n",
    "            \"legalentityhistorync\")\n",
    "\n",
    "    organization_agg_nc = hiveContext.table(\n",
    "        \"organization_history_nc\").withColumnRenamed(\n",
    "            \"recent_total_nccount\",\n",
    "            \"organizationhistorync\")\n",
    "\n",
    "    employee_agg_nc = hiveContext.table(\n",
    "        \"employee_history_nc\").withColumnRenamed(\n",
    "            \"recent_total_nccount\",\n",
    "            \"employeehistorync\")\n",
    "\n",
    "    employee_agg_expense = hiveContext.table(\n",
    "        \"employee_history_expense\").withColumnRenamed(\n",
    "            \"recent_total_expense\",\n",
    "            \"employeerecentexpense\")\n",
    "\n",
    "    employee_agg_quantity = hiveContext.table(\n",
    "        \"employee_history_quantity\").withColumnRenamed(\n",
    "            \"recent_total_quantity\",\n",
    "            \"employeerecentexpensequantity\")\n",
    "\n",
    "    # join 4 nc history features and 2 employee expense features\n",
    "    df_feature_data = df_feature_data.join(\n",
    "        costcenter_agg_nc,\n",
    "        [\"cid_dbsn\",\"costcentercode\"],\n",
    "        \"left_outer\").join(\n",
    "            legalentity_agg_nc,\n",
    "            [\"cid_dbsn\",\"legalentitycode\"],\n",
    "            \"left_outer\").join(\n",
    "                organization_agg_nc,\n",
    "                [\"cid_dbsn\",\"organizationcode\"],\n",
    "                \"left_outer\" ).join(\n",
    "                    employee_agg_nc,\n",
    "                    [\"cid_dbsn\",\"appemployeename\"],\n",
    "                    \"left_outer\").join(\n",
    "                        employee_agg_expense,\n",
    "                        [\"cid_dbsn\",\"appemployeename\"],\n",
    "                        \"left_outer\").join(\n",
    "                            employee_agg_quantity,\n",
    "                            [\"cid_dbsn\",\"appemployeename\"],\n",
    "                            \"left_outer\")\n",
    "\n",
    "    if is_realtime:\n",
    "        df_feature_data= df_feature_data.withColumn(\n",
    "            \"isnc\",\n",
    "            F.isnull(df_feature_data[\"uid\"]))\n",
    "\n",
    "    df_features = df_feature_data.fillna(\n",
    "            {'duration': 1,\n",
    "             'totalexpensequantity': 1,\n",
    "             'costcenterhistorync': 0,\n",
    "             'legalentityhistorync': 0,\n",
    "             'organizationhistorync': 0,\n",
    "             'employeehistorync': 0,\n",
    "             'employeerecentexpense': 0.0,\n",
    "             'employeerecentexpensequantity': 0.0,\n",
    "             # category\n",
    "             'uid':\"null\",\n",
    "             'reimbursementId':\"null\",\n",
    "             'allocationType':\"null\",\n",
    "             'applicantLevel':\"null\",\n",
    "             'legalEntityCode':\"null\",\n",
    "             'regionCode':\"null\",\n",
    "             'appEmployeeName':\"null\",\n",
    "             'costCenterCode':\"null\",\n",
    "             'organizationCode':\"null\",\n",
    "             'vendorCode':\"null\",\n",
    "             'expenseId':\"null\",\n",
    "             'city':\"null\",\n",
    "             'destination':\"null\",\n",
    "             'expensePaymentType':\"null\",\n",
    "             'flightNo':\"null\",\n",
    "             'mileage':\"null\",\n",
    "             'placeOfDeparture':\"null\",\n",
    "             'transportation':\"null\",\n",
    "             'expenseTypeCode':\"null\",\n",
    "             'expenseTypeName':\"null\",\n",
    "             'cid_dbsn':\"null\",\n",
    "             # text\n",
    "             'comments':\"null\",\n",
    "             'deductDemo':\"null\",\n",
    "             'subject':\"null\",\n",
    "             'expenseDescription':\"null\",\n",
    "             'purpose':\"null\",\n",
    "             # numeric\n",
    "             'cashAdvance':0.0,\n",
    "             'deductAmount':0.0,\n",
    "             'paidByCompany':0.0,\n",
    "             'totalBalanceOfReceivable':0.0,\n",
    "             'totalPayableAmount':0.0,\n",
    "             'totalReimbursementAmount':0.0,\n",
    "             'applyExpenseAmount':0.0,\n",
    "             'expenditure':0.0,\n",
    "             'quantity':1.0,\n",
    "             'unitPrice':0.0,\n",
    "             # bool\n",
    "             'isPurchase':False,\n",
    "             'isRoundTrip':False,\n",
    "             'isHighRisk':False,\n",
    "             'isnc': False})\n",
    "\n",
    "    df_features = normalize_features(df_features)\n",
    "\n",
    "    columns=[\n",
    "        \"uid\",\n",
    "        \"allocationtype\",\n",
    "        \"appemployeename\",\n",
    "        \"applicantlevel\",\n",
    "        \"applyexpenseamount\",\n",
    "        \"begindate\",\n",
    "        \"cashadvance\",\n",
    "        \"city\",\n",
    "        \"comments\",\n",
    "        \"costcentercode\",\n",
    "        \"deductamount\",\n",
    "        \"deductdemo\",\n",
    "        \"destination\",\n",
    "        \"enddate\",\n",
    "        \"expenditure\",\n",
    "        \"expensedescription\",\n",
    "        \"expenseid\",\n",
    "        \"expensepaymenttype\",\n",
    "        \"expensetypecode\",\n",
    "        \"expensetypename\",\n",
    "        \"flightno\",\n",
    "        \"ispurchase\",\n",
    "        \"isroundtrip\",\n",
    "        \"legalentitycode\",\n",
    "        \"mileage\",\n",
    "        \"organizationcode\",\n",
    "        \"paidbycompany\",\n",
    "        \"placeofdeparture\",\n",
    "        \"purpose\",\n",
    "        \"quantity\",\n",
    "        \"regioncode\",\n",
    "        \"reimbursementid\",\n",
    "        \"subject\",\n",
    "        \"submitted_date\",\n",
    "        \"totalbalanceofreceivable\",\n",
    "        \"totalpayableamount\",\n",
    "        \"totalreimbursementamount\",\n",
    "        \"transportation\",\n",
    "        \"unitprice\",\n",
    "        \"vendorcode\",\n",
    "        \"cid_dbsn\",\n",
    "        \"duration\",\n",
    "        \"totalexpensequantity\",\n",
    "        \"costcenterhistorync\",\n",
    "        \"legalentityhistorync\",\n",
    "        \"organizationhistorync\",\n",
    "        \"employeehistorync\",\n",
    "        \"employeerecentexpense\",\n",
    "        \"employeerecentexpensequantity\",\n",
    "        \"isnc\"\n",
    "    ]\n",
    "\n",
    "    return df_features.select(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_history_data = hiveContext.table(\"history_record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hist_d=500\n",
    "df_clean_data = df_history_data.withColumn(\n",
    "        \"historydays\",\n",
    "        F.datediff(\n",
    "            F.lit(current_date),\n",
    "            F.date_format(df_history_data[\"applyDate\"],\"yyyy-MM-dd\"))\n",
    ")\n",
    "# select recent 3 month history data to do feature engineering\n",
    "# df_recent3m_history = df_clean_data.filter(df_clean_data[\"historydays\"] < Hist_d).dropDuplicates(['uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_features = get_features(df_clean_data, hiveContext, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_features.write.insertInto(\"feature\",overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import argparse\n",
    "from argparse import RawTextHelpFormatter\n",
    "import re\n",
    "\n",
    "from pyspark import HiveContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.types import DoubleType, IntegerType, BooleanType, StringType, NullType, DateType, TimestampType\n",
    "import h2o\n",
    "from pysparkling import *\n",
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "description= \"\"\n",
    "epilog= \"\"\n",
    "APP_NAME= \"pyspark_model\"\n",
    "MODEL_PATH= \"/Volumes/data/Dropbox/Accenture/TnE_from_QianWei/source/analysis/model_save/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quiet_py4j():\n",
    "    \"\"\" turn down spark logging for the test context \"\"\"\n",
    "    logger = logging.getLogger('py4j')\n",
    "    logger.setLevel(logging.ERROR)\n",
    "\n",
    "def spark_context():\n",
    "    \"\"\" fixture for creating a spark context\n",
    "    Args:\n",
    "        request: pytest.FixtureRequest object\n",
    "    \"\"\"\n",
    "    conf = (SparkConf().setAppName(APP_NAME))\n",
    "    sc = SparkContext(conf=conf)\n",
    "    quiet_py4j()\n",
    "    return sc\n",
    "\n",
    "def decode_string(x):\n",
    "    x= unicode(x)\n",
    "    for pair in re.findall(r'(\\<0x(\\w+)\\>)',x):\n",
    "        if pair == []:\n",
    "            return x\n",
    "        else:\n",
    "            full, part = pair\n",
    "            x = x.replace(full,part.decode(\"hex\").decode(\"utf8\"))\n",
    "\n",
    "    return x\n",
    "\n",
    "def set_model_path(db):\n",
    "    global MODEL_PATH\n",
    "    MODEL_PATH = MODEL_PATH + db + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_n_prediction(df_feature, df_feature_h2o, sc, hiveContext, hc):\n",
    "\n",
    "    x= [#\"allocationtype\",\n",
    "        \"applicantlevel\",\n",
    "        #\"legalentitycode\", \"regioncode\",\n",
    "        \"appemployeename\", #\"costcentercode\",\n",
    "        \"organizationcode\",# \"vendorcode\",\n",
    "        #\"city\", \"destination\", \"expensepaymenttype\", \"flightno\",\n",
    "        #\"mileage\", \"placeofdeparture\", \"transportation\",\n",
    "        \"expensetypename\",\n",
    "        \"cid_dbsn\", \"duration\", #\"costcenterhistorync\", \"legalentityhistorync\",\n",
    "        \"organizationhistorync\",\n",
    "        \"employeehistorync\", \"cashadvance\", \"deductamount\",\n",
    "        #\"paidbycompany\", \"totalbalanceofreceivable\", \"totalpayableamount\",\n",
    "        \"totalreimbursementamount\",\n",
    "        \"applyexpenseamount\",\n",
    "        #\"expenditure\", \"quantity\", \"unitprice\",\n",
    "        #\"totalexpensequantity\",\n",
    "        \"employeerecentexpense\"\n",
    "        #\"employeerecentexpensequantity\",\n",
    "        #\"ispurchase\", \"isroundtrip\",\n",
    "        #\"date_span\"\n",
    "    ]\n",
    "\n",
    "    dl_model = H2OAutoEncoderEstimator(hidden = [100, 80, 50, 80, 100],\n",
    "                                    activation = \"Tanh\",\n",
    "                                    variable_importances =True,\n",
    "                                    epochs = 100,\n",
    "                                    seed = 123\n",
    "                                    )\n",
    "\n",
    "    dl_model.train(\n",
    "            x               = x,\n",
    "            training_frame  = df_feature_h2o,\n",
    "    )\n",
    "\n",
    "    # Save model into \"autoencoder.model\"\n",
    "    print MODEL_PATH\n",
    "    model_path = h2o.save_model(dl_model, path=MODEL_PATH, force=True)\n",
    "    sc.parallelize([model_path]).saveAsPickleFile(MODEL_PATH+'model_path')\n",
    "    print \"Daily process >> building DL model: {}\".format(\"done!\")\n",
    "\n",
    "    df_mse_h2o = dl_model.anomaly(df_feature_h2o, per_feature=False)\n",
    "    df_cbind = df_feature_h2o[\"uid\"].cbind(df_mse_h2o)\n",
    "    df_tmp = hc.as_spark_frame(df_cbind)\n",
    "    print \"expenseid_mse row numbers = {}\".format(df_tmp.count())\n",
    "\n",
    "    df_prediction = df_feature.join(df_tmp, on= \"uid\", how= \"left_outer\")\n",
    "    df_prediction = df_prediction.withColumnRenamed(\"Reconstruction.MSE\",\"riskscore\")\n",
    "\n",
    "    # TODO:110 Save combined data into \"prediction_history\"\n",
    "    df_prediction = hiveContext.createDataFrame(df_prediction.rdd, df_prediction.schema)\n",
    "    columns = [\n",
    "        \"uid\",\n",
    "        \"allocationtype\",\n",
    "        \"appemployeename\",\n",
    "        \"applicantlevel\",\n",
    "        \"applyexpenseamount\",\n",
    "        \"begindate\",\n",
    "        \"cashadvance\",\n",
    "        \"city\",\n",
    "        \"costcentercode\",\n",
    "        \"deductamount\",\n",
    "        \"destination\",\n",
    "        \"enddate\",\n",
    "        \"expenditure\",\n",
    "        \"expenseid\",\n",
    "        \"expensepaymenttype\",\n",
    "        \"expensetypename\",\n",
    "        \"flightno\",\n",
    "        \"ispurchase\",\n",
    "        \"isroundtrip\",\n",
    "        \"legalentitycode\",\n",
    "        \"mileage\",\n",
    "        \"organizationcode\",\n",
    "        \"paidbycompany\",\n",
    "        \"placeofdeparture\",\n",
    "        \"quantity\",\n",
    "        \"regioncode\",\n",
    "        \"reimbursementid\",\n",
    "        \"submitted_date\",\n",
    "        \"totalbalanceofreceivable\",\n",
    "        \"totalpayableamount\",\n",
    "        \"totalreimbursementamount\",\n",
    "        \"transportation\",\n",
    "        \"unitprice\",\n",
    "        \"vendorcode\",\n",
    "        \"duration\",\n",
    "        # \"totalexpensequantity\",\n",
    "        \"costcenterhistorync\",\n",
    "        \"legalentityhistorync\",\n",
    "        \"organizationhistorync\",\n",
    "        \"employeehistorync\",\n",
    "        \"employeerecentexpense\",\n",
    "        \"employeerecentexpensequantity\",\n",
    "        \"cid_dbsn\",\n",
    "        \"riskscore\",\n",
    "        \"isnc\"\n",
    "    ]\n",
    "\n",
    "    # DONE:100 Save feature importance into table \"feature_importance\"\n",
    "    df_feature_imp= hiveContext.createDataFrame(dl_model.varimp(use_pandas = True)) # as_spark_dataframe\n",
    "    print \"df_prediction row numbers = {}\".format(df_prediction.count())\n",
    "\n",
    "    return df_prediction.select(columns), df_feature_imp, dl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_h2o_features(df_feature, hc):\n",
    "    df_feature_h2o = hc.as_h2o_frame(df_feature.drop(\"begindate\").drop(\"enddate\"),\"featureTable\")\n",
    "    return df_feature_h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(df_feature, dl_model, df_feature_h2o, sc, hiveContext, hc, is_realtime):\n",
    "    #model_path = sc.pickleFile(MODEL_PATH+'model_path').collect()[0]\n",
    "    #print model_path\n",
    "    #dl_model = h2o.load_model(model_path)\n",
    "\n",
    "    # DONE:90 Combine MSE with features as_data_frame(True)\n",
    "    df_mse_h2o = dl_model.anomaly(df_feature_h2o, per_feature=False)\n",
    "    df_cbind = df_feature_h2o[\"uid\"].cbind(df_mse_h2o)\n",
    "    df_tmp = hc.as_spark_frame(df_cbind)\n",
    "    print \"expenseid_mse row numbers = {}\".format(df_tmp.count())\n",
    "\n",
    "    df_prediction = df_feature.join(df_tmp, on= \"uid\", how= \"left_outer\")\n",
    "    df_prediction = df_prediction.withColumnRenamed(\"Reconstruction.MSE\",\"riskscore\")\n",
    "\n",
    "    # transform data type\n",
    "    df_prediction = df_prediction.withColumn(\"begindate\",F.to_date(df_prediction[\"begindate\"])) \\\n",
    "        .withColumn(\"enddate\",F.to_date(df_prediction[\"enddate\"]))\n",
    "\n",
    "    ## Features\n",
    "    int_variables = [\n",
    "        \"duration\",\n",
    "        \"costcenterhistorync\",\n",
    "        \"legalentityhistorync\",\n",
    "        \"organizationhistorync\",\n",
    "        \"employeehistorync\"\n",
    "    ]\n",
    "\n",
    "    double_variables = [\n",
    "        \"cashadvance\",\n",
    "        \"deductamount\",\n",
    "        \"paidbycompany\",\n",
    "        \"totalbalanceofreceivable\",\n",
    "        \"totalpayableamount\",\n",
    "        \"totalreimbursementamount\",\n",
    "        \"applyexpenseamount\",\n",
    "        \"expenditure\",\n",
    "        \"quantity\",\n",
    "        \"unitprice\",\n",
    "        \"employeerecentexpense\",\n",
    "        \"employeerecentexpensequantity\"\n",
    "    ]\n",
    "\n",
    "    bool_variables = [\n",
    "        \"ispurchase\",\n",
    "        \"isroundtrip\"\n",
    "    ]\n",
    "\n",
    "    for tmp_col in int_variables:\n",
    "        df_prediction = df_prediction.withColumn(tmp_col, df_prediction[tmp_col].cast(\"int\"))\n",
    "\n",
    "    for tmp_col in double_variables:\n",
    "        df_prediction = df_prediction.withColumn(tmp_col, df_prediction[tmp_col].cast(\"double\"))\n",
    "\n",
    "    for tmp_col in bool_variables:\n",
    "        df_prediction = df_prediction.withColumn(tmp_col, df_prediction[tmp_col].cast(\"boolean\"))\n",
    "\n",
    "    # TODO:110 Save combined data into \"prediction_history\"\n",
    "    df_prediction = df_prediction.sort(df_prediction[\"riskscore\"].desc())\n",
    "    df_prediction = hiveContext.createDataFrame(df_prediction.rdd,df_prediction.schema)\n",
    "    columns = [\n",
    "        \"uid\",\n",
    "        \"allocationtype\",\n",
    "        \"appemployeename\",\n",
    "        \"applicantlevel\",\n",
    "        \"applyexpenseamount\",\n",
    "        \"begindate\",\n",
    "        \"cashadvance\",\n",
    "        \"city\",\n",
    "        \"costcentercode\",\n",
    "        \"deductamount\",\n",
    "        \"destination\",\n",
    "        \"enddate\",\n",
    "        \"expenditure\",\n",
    "        \"expenseid\",\n",
    "        \"expensepaymenttype\",\n",
    "        \"expensetypename\",\n",
    "        \"flightno\",\n",
    "        \"ispurchase\",\n",
    "        \"isroundtrip\",\n",
    "        \"legalentitycode\",\n",
    "        \"mileage\",\n",
    "        \"organizationcode\",\n",
    "        \"paidbycompany\",\n",
    "        \"placeofdeparture\",\n",
    "        \"quantity\",\n",
    "        \"regioncode\",\n",
    "        \"reimbursementid\",\n",
    "        \"submitted_date\",\n",
    "        \"totalbalanceofreceivable\",\n",
    "        \"totalpayableamount\",\n",
    "        \"totalreimbursementamount\",\n",
    "        \"transportation\",\n",
    "        \"unitprice\",\n",
    "        \"vendorcode\",\n",
    "        \"duration\",\n",
    "        \"costcenterhistorync\",\n",
    "        \"legalentityhistorync\",\n",
    "        \"organizationhistorync\",\n",
    "        \"employeehistorync\",\n",
    "        \"employeerecentexpense\",\n",
    "        \"employeerecentexpensequantity\",\n",
    "        \"cid_dbsn\",\n",
    "        \"riskscore\",\n",
    "        \"isnc\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    # DONE:100 Save feature importance into table \"feature_importance\"\n",
    "    df_feature_imp= hiveContext.createDataFrame(dl_model.varimp(use_pandas = True)) # as_spark_dataframe\n",
    "    decode = F.udf(decode_string, StringType())\n",
    "    df_feature_imp = df_feature_imp.withColumn(\"variable\",decode(df_feature_imp[\"variable\"]))\n",
    "    df_feature_imp.show()\n",
    "\n",
    "    return (df_prediction.select(columns),df_feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature  = hiveContext.table(\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pysparkling/context.py:111: UserWarning: Method H2OContext.getOrCreate with argument of type SparkContext is deprecated and parameter of type SparkSession is preferred.\n",
      "  \"parameter of type SparkSession is preferred.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://10.202.27.15:54323... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>12 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.4.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>22 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>sparkling-water-huaijianzhang_local-1497244438411</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>910 Mb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://10.202.27.15:54323</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.13 final</td></tr></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc = H2OContext.getOrCreate(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hive_df_feature  = hiveContext.table(\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique uid number = 1000\n"
     ]
    }
   ],
   "source": [
    "l = hive_df_feature.select(\"uid\").distinct().count()\n",
    "print \"unique uid number = {}\".format(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_h2o = get_h2o_features(hive_df_feature, hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 48]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_h2o.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>uid             </th><th>allocationtype  </th><th>appemployeename   </th><th style=\"text-align: right;\">  applicantlevel</th><th style=\"text-align: right;\">  applyexpenseamount</th><th style=\"text-align: right;\">  cashadvance</th><th>city  </th><th>comments                               </th><th style=\"text-align: right;\">  costcentercode</th><th style=\"text-align: right;\">  deductamount</th><th>deductdemo  </th><th>destination  </th><th style=\"text-align: right;\">  expenditure</th><th>expensedescription  </th><th style=\"text-align: right;\">  expenseId</th><th>expensepaymenttype  </th><th>expensetypecode  </th><th>expensetypename                           </th><th>flightno  </th><th style=\"text-align: right;\">  ispurchase</th><th style=\"text-align: right;\">  isroundtrip</th><th>legalentitycode  </th><th>mileage  </th><th style=\"text-align: right;\">  organizationcode</th><th style=\"text-align: right;\">  paidbycompany</th><th>placeofdeparture  </th><th>purpose  </th><th style=\"text-align: right;\">  quantity</th><th>regioncode  </th><th style=\"text-align: right;\">  reimbursementId</th><th>subject  </th><th>submitted_date  </th><th style=\"text-align: right;\">  totalbalanceofreceivable</th><th style=\"text-align: right;\">  totalpayableamount</th><th style=\"text-align: right;\">  totalreimbursementamount</th><th>transportation  </th><th style=\"text-align: right;\">  unitprice</th><th>vendorcode  </th><th>cid_dbsn  </th><th style=\"text-align: right;\">  duration</th><th style=\"text-align: right;\">  totalExpenseQuantity</th><th style=\"text-align: right;\">  costCenterHistoryNC</th><th style=\"text-align: right;\">  legalEntityHistoryNC</th><th style=\"text-align: right;\">  organizationHistoryNC</th><th style=\"text-align: right;\">  employeeHistoryNC</th><th style=\"text-align: right;\">  employeeRecentExpense</th><th style=\"text-align: right;\">  employeeRecentExpenseQuantity</th><th style=\"text-align: right;\">  isnc</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>2_4|12670|103706</td><td>报销单分摊      </td><td>disenzhang(张东轩)</td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             3.04452</td><td style=\"text-align: right;\">            0</td><td>      </td><td>2016年1月26日-2016年3月25日，交通费报销</td><td style=\"text-align: right;\">           21003</td><td style=\"text-align: right;\">             0</td><td>null        </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">     103706</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21003</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">            12670</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             4.82831</td><td style=\"text-align: right;\">                   4.82831</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                4.82831</td><td style=\"text-align: right;\">                              6</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "<tr><td>2_4|12670|103705</td><td>报销单分摊      </td><td>disenzhang(张东轩)</td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             3.21888</td><td style=\"text-align: right;\">            0</td><td>      </td><td>2016年1月26日-2016年3月25日，交通费报销</td><td style=\"text-align: right;\">           21003</td><td style=\"text-align: right;\">             0</td><td>null        </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">     103705</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21003</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">            12670</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             4.82831</td><td style=\"text-align: right;\">                   4.82831</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                4.82831</td><td style=\"text-align: right;\">                              6</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "<tr><td>2_4|12670|103708</td><td>报销单分摊      </td><td>disenzhang(张东轩)</td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             3.04452</td><td style=\"text-align: right;\">            0</td><td>      </td><td>2016年1月26日-2016年3月25日，交通费报销</td><td style=\"text-align: right;\">           21003</td><td style=\"text-align: right;\">             0</td><td>null        </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">     103708</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21003</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">            12670</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             4.82831</td><td style=\"text-align: right;\">                   4.82831</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                4.82831</td><td style=\"text-align: right;\">                              6</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "<tr><td>2_4|12670|103704</td><td>报销单分摊      </td><td>disenzhang(张东轩)</td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             2.99573</td><td style=\"text-align: right;\">            0</td><td>      </td><td>2016年1月26日-2016年3月25日，交通费报销</td><td style=\"text-align: right;\">           21003</td><td style=\"text-align: right;\">             0</td><td>null        </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">     103704</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21003</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">            12670</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             4.82831</td><td style=\"text-align: right;\">                   4.82831</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                4.82831</td><td style=\"text-align: right;\">                              6</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "<tr><td>2_4|12670|103707</td><td>报销单分摊      </td><td>disenzhang(张东轩)</td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             3.09104</td><td style=\"text-align: right;\">            0</td><td>      </td><td>2016年1月26日-2016年3月25日，交通费报销</td><td style=\"text-align: right;\">           21003</td><td style=\"text-align: right;\">             0</td><td>null        </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">     103707</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21003</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">            12670</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             4.82831</td><td style=\"text-align: right;\">                   4.82831</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                4.82831</td><td style=\"text-align: right;\">                              6</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "<tr><td>2_4|12670|103709</td><td>报销单分摊      </td><td>disenzhang(张东轩)</td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             3.04452</td><td style=\"text-align: right;\">            0</td><td>      </td><td>2016年1月26日-2016年3月25日，交通费报销</td><td style=\"text-align: right;\">           21003</td><td style=\"text-align: right;\">             0</td><td>null        </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">     103709</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21003</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">            12670</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             4.82831</td><td style=\"text-align: right;\">                   4.82831</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                4.82831</td><td style=\"text-align: right;\">                              6</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "<tr><td>2_4|2482|13701  </td><td>报销单分摊      </td><td>kevinxhxu(许辉旭) </td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             3.3673 </td><td style=\"text-align: right;\">            0</td><td>      </td><td>2015.12-2016.04加班打车报销            </td><td style=\"text-align: right;\">           21106</td><td style=\"text-align: right;\">             0</td><td>            </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">      13701</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21106</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">             2482</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             7.47647</td><td style=\"text-align: right;\">                   7.47647</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                7.47647</td><td style=\"text-align: right;\">                             46</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "<tr><td>2_4|2482|13712  </td><td>报销单分摊      </td><td>kevinxhxu(许辉旭) </td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             3.3673 </td><td style=\"text-align: right;\">            0</td><td>      </td><td>2015.12-2016.04加班打车报销            </td><td style=\"text-align: right;\">           21106</td><td style=\"text-align: right;\">             0</td><td>            </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">      13712</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21106</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">             2482</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             7.47647</td><td style=\"text-align: right;\">                   7.47647</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                7.47647</td><td style=\"text-align: right;\">                             46</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "<tr><td>2_4|2482|13702  </td><td>报销单分摊      </td><td>kevinxhxu(许辉旭) </td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             2.77259</td><td style=\"text-align: right;\">            0</td><td>      </td><td>2015.12-2016.04加班打车报销            </td><td style=\"text-align: right;\">           21106</td><td style=\"text-align: right;\">             0</td><td>            </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">      13702</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21106</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">             2482</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             7.47647</td><td style=\"text-align: right;\">                   7.47647</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                7.47647</td><td style=\"text-align: right;\">                             46</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "<tr><td>2_4|2482|13729  </td><td>报销单分摊      </td><td>kevinxhxu(许辉旭) </td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">             4.02535</td><td style=\"text-align: right;\">            0</td><td>      </td><td>2015.12-2016.04加班打车报销            </td><td style=\"text-align: right;\">           21106</td><td style=\"text-align: right;\">             0</td><td>            </td><td>             </td><td style=\"text-align: right;\">            0</td><td>                    </td><td style=\"text-align: right;\">      13729</td><td>                    </td><td>                 </td><td>市内交通费_夜间及其他市内交通费_夜间交通费</td><td>          </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td>T01              </td><td>         </td><td style=\"text-align: right;\">             21106</td><td style=\"text-align: right;\">              0</td><td>                  </td><td>         </td><td style=\"text-align: right;\">         1</td><td>            </td><td style=\"text-align: right;\">             2482</td><td>         </td><td>20161019_12     </td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">             7.47647</td><td style=\"text-align: right;\">                   7.47647</td><td>                </td><td style=\"text-align: right;\">          0</td><td>null        </td><td>2_4       </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    46</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                  0</td><td style=\"text-align: right;\">                7.47647</td><td style=\"text-align: right;\">                             46</td><td style=\"text-align: right;\">     0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_h2o.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_variables = [\n",
    "        \"allocationtype\",\n",
    "        \"applicantlevel\",\n",
    "        \"legalentitycode\",\n",
    "        \"regioncode\",\n",
    "        \"appemployeename\",\n",
    "#        \"costcentercode\",\n",
    "        \"organizationcode\",\n",
    "        \"vendorcode\",\n",
    "        \"city\",\n",
    "        \"destination\",\n",
    "        \"expensepaymenttype\",\n",
    "        \"flightno\",\n",
    "        \"mileage\",\n",
    "        \"placeofdeparture\",\n",
    "        \"transportation\",\n",
    "        \"expensetypename\",\n",
    "        \"cid_dbsn\"\n",
    "    ]\n",
    "\n",
    "    int_variables = [\n",
    "        \"duration\",\n",
    "#        \"costcenterhistorync\",\n",
    "#        \"legalentityhistorync\",\n",
    "#        \"organizationhistorync\",\n",
    "#        \"employeehistorync\"\n",
    "    ]\n",
    "\n",
    "    double_variables = [\n",
    "        \"cashadvance\",\n",
    "        \"deductamount\",\n",
    "        \"paidbycompany\",\n",
    "        \"totalbalanceofreceivable\",\n",
    "        \"totalpayableamount\",\n",
    "        \"totalreimbursementamount\",\n",
    "        \"applyexpenseamount\",\n",
    "        \"expenditure\",\n",
    "        \"quantity\",\n",
    "        \"unitprice\",\n",
    "#        \"totalexpensequantity\",\n",
    "#        \"employeerecentexpense\",\n",
    "#        \"employeerecentexpensequantity\"\n",
    "    ]\n",
    "\n",
    "    bool_variables = [\n",
    "        \"ispurchase\",\n",
    "        \"isroundtrip\"\n",
    "    ]\n",
    "\n",
    "    date_variables = [\n",
    "        \"begindate\",\n",
    "        \"enddate\"\n",
    "    ]\n",
    "\n",
    "    x = []\n",
    "    x.extend(category_variables)\n",
    "    x.extend(int_variables)\n",
    "    x.extend(double_variables)\n",
    "    x.extend(bool_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "expenseid_mse row numbers = 1000\n",
      "+--------------------+-------------------+------------------+-------------------+\n",
      "|            variable|relative_importance| scaled_importance|         percentage|\n",
      "+--------------------+-------------------+------------------+-------------------+\n",
      "|        deductamount|                1.0|               1.0|0.22254268262497925|\n",
      "|  applyexpenseamount| 0.9618339538574219|0.9618339538574219|0.21404910833122118|\n",
      "|            duration| 0.9356208443641663|0.9356208443641663|0.20821557262464976|\n",
      "|totalreimbursemen...| 0.8018185496330261|0.8018185496330261| 0.1784388510138037|\n",
      "|  totalpayableamount| 0.7942466735839844|0.7942466735839844|0.17675378540534611|\n",
      "+--------------------+-------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# autoencoder\n",
    "dl_model = H2OAutoEncoderEstimator(hidden = [200, 100, 50, 100, 200],\n",
    "                                activation = \"Tanh\",\n",
    "                                variable_importances =True,\n",
    "                                epochs = 10,\n",
    "                                seed = 123\n",
    "                                )\n",
    "dl_model.train(\n",
    "        x               = x,\n",
    "        training_frame  = df_feature_h2o,\n",
    ")\n",
    "\n",
    "df_prediction, df_feature_imp = get_prediction(df_feature, dl_model, df_feature_h2o, sc, hiveContext, hc, 0)\n",
    "#print df_feature_h2o.describe()\n",
    "df_prediction, df_feature_imp = get_prediction(df_feature, dl_model, df_feature_h2o, sc, hiveContext, hc, 0)\n",
    "\n",
    "print \"df_prediction row numbers = {}\".format(df_prediction.count())\n",
    "\n",
    "df_prediction.write.insertInto(\"prediction_history\", overwrite= True)\n",
    "df_feature_imp.write.insertInto(\"feature_importance\", overwrite = True)\n",
    "\n",
    "print \"Daily process >> save important features: {}\".format(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand,when\n",
    "df_feature_label = df_feature.withColumn('label', when(rand() > 0.7, 1).otherwise(0))\n",
    "df_feature_label_h2o = hc.as_h2o_frame(df_feature_label)\n",
    "y = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator, H2ODeepLearningEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "\n",
    "dl_model2 = H2ODeepLearningEstimator(hidden = [200, 100, 50, 100, 200],\n",
    "                                activation = \"Tanh\",\n",
    "                                variable_importances = True,\n",
    "                                epochs = 10,\n",
    "                                seed = 123)\n",
    "dl_model2.train(\n",
    "        x               = x,\n",
    "        y               = y,\n",
    "        training_frame  = df_feature_label_h2o,\n",
    ")\n",
    "predicted = dl_model2.predict(test_data=df_feature_label_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gb_model = H2OGradientBoostingEstimator()\n",
    "gb_model.train(\n",
    "        x               = x,\n",
    "        y               = y,\n",
    "        training_frame  = df_feature_label_h2o,\n",
    ")\n",
    "predicted = gb_model.predict(test_data=df_feature_label_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 1]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expenseid_mse row numbers = 1000\n",
      "+--------------------+-------------------+------------------+-------------------+\n",
      "|            variable|relative_importance| scaled_importance|         percentage|\n",
      "+--------------------+-------------------+------------------+-------------------+\n",
      "|        deductamount|                1.0|               1.0|0.21874546106078435|\n",
      "|  applyexpenseamount| 0.9875599145889282|0.9875599145889282| 0.2160242488419039|\n",
      "|            duration|  0.949902355670929| 0.949902355670929| 0.2077868287539625|\n",
      "|  totalpayableamount| 0.8233636617660522|0.8233636617660522| 0.1801070638137108|\n",
      "|totalreimbursemen...| 0.8106974959373474|0.8106974959373474| 0.1773363975296384|\n",
      "+--------------------+-------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expenseid_mse row numbers = 1000\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "u'Cannot resolve column name \"_1\" among (variable, relative_importance, scaled_importance, percentage);'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-7a39f179fb6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print df_feature_h2o.describe()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_feature_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_feature_h2o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiveContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"df_prediction row numbers = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-18558f5d61a8>\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(df_feature, dl_model, df_feature_h2o, sc, hiveContext, hc, is_realtime)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mdf_feature_imp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhiveContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvarimp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_pandas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# as_spark_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mdecode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mdf_feature_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_feature_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_feature_imp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mdf_feature_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/spark-2.1.0/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \"\"\"\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/spark-2.1.0/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/spark-2.1.0/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u'Cannot resolve column name \"_1\" among (variable, relative_importance, scaled_importance, percentage);'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(uid=u'2_4|12670|103706', allocationtype=u'\\u62a5\\u9500\\u5355\\u5206\\u644a', appemployeename=u'disenzhang(\\u5f20\\u4e1c\\u8f69)', applicantlevel=u'2', applyexpenseamount=3.044522437723423, begindate=datetime.date(2016, 3, 7), cashadvance=0.0, city=u'', comments=u'2016\\u5e741\\u670826\\u65e5-2016\\u5e743\\u670825\\u65e5\\uff0c\\u4ea4\\u901a\\u8d39\\u62a5\\u9500', costcentercode=u'21003', deductamount=0.0, deductdemo=u'null', destination=u'', enddate=datetime.date(2016, 3, 7), expenditure=0.0, expensedescription=u'', expenseId=u'103706', expensepaymenttype=u'', expensetypecode=u'', expensetypename=u'\\u5e02\\u5185\\u4ea4\\u901a\\u8d39_\\u591c\\u95f4\\u53ca\\u5176\\u4ed6\\u5e02\\u5185\\u4ea4\\u901a\\u8d39_\\u591c\\u95f4\\u4ea4\\u901a\\u8d39', flightno=u'', ispurchase=False, isroundtrip=False, legalentitycode=u'T01', mileage=u'', organizationcode=u'21003', paidbycompany=0.0, placeofdeparture=u'', purpose=u'', quantity=1.0, regioncode=u'', reimbursementId=u'12670', subject=u'', submitted_date=u'20161019_12', totalbalanceofreceivable=0.0, totalpayableamount=4.8283137373023015, totalreimbursementamount=4.8283137373023015, transportation=u'', unitprice=0.0, vendorcode=u'null', cid_dbsn=u'2_4', duration=1, totalExpenseQuantity=6.0, costCenterHistoryNC=0, legalEntityHistoryNC=230, organizationHistoryNC=0, employeeHistoryNC=0, employeeRecentExpense=6.431331081933479, employeeRecentExpenseQuantity=30.0, isnc=False)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                   biases['encoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "                                   biases['encoder_b2']))\n",
    "\n",
    "    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['encoder_h3']),\n",
    "                                   biases['encoder_b3']))\n",
    "    return layer_3\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #0\n",
    "    layer_0 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h0']),\n",
    "                                   biases['decoder_b0']))\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(layer_0, weights['decoder_h1']),\n",
    "                                   biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "                                   biases['decoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if cost == \"mse\":\n",
    "    cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, c = sess.run([optimizer, cost], feed_dict={X: input_df_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_df_feature = df_feature.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid is not float\n",
      "allocationtype is not float\n",
      "appemployeename is not float\n",
      "+ applicantlevel is included\n",
      "+ applyexpenseamount is included\n",
      "begindate is not float\n",
      "+ cashadvance is included\n",
      "city is not float\n",
      "comments is not float\n",
      "costcentercode is not float\n",
      "+ deductamount is included\n",
      "deductdemo is not float\n",
      "destination is not float\n",
      "enddate is not float\n",
      "+ expenditure is included\n",
      "expensedescription is not float\n",
      "+ expenseId is included\n",
      "expensepaymenttype is not float\n",
      "expensetypecode is not float\n",
      "expensetypename is not float\n",
      "flightno is not float\n",
      "+ ispurchase is included\n",
      "+ isroundtrip is included\n",
      "legalentitycode is not float\n",
      "mileage is not float\n",
      "organizationcode is not float\n",
      "+ paidbycompany is included\n",
      "placeofdeparture is not float\n",
      "purpose is not float\n",
      "+ quantity is included\n",
      "regioncode is not float\n",
      "+ reimbursementId is included\n",
      "subject is not float\n",
      "submitted_date is not float\n",
      "+ totalbalanceofreceivable is included\n",
      "+ totalpayableamount is included\n",
      "+ totalreimbursementamount is included\n",
      "transportation is not float\n",
      "+ unitprice is included\n",
      "vendorcode is not float\n",
      "cid_dbsn is not float\n",
      "+ duration is included\n",
      "+ totalExpenseQuantity is included\n",
      "+ costCenterHistoryNC is included\n",
      "+ legalEntityHistoryNC is included\n",
      "+ organizationHistoryNC is included\n",
      "+ employeeHistoryNC is included\n",
      "+ employeeRecentExpense is included\n",
      "+ employeeRecentExpenseQuantity is included\n",
      "+ isnc is included\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, c = sess.run([optimizer, cost], feed_dict={X: input_df_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.394297e+08"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
